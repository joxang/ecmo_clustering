{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import ttest_ind \n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmodf = pd.read_csv('data/ecmo.csv', index_col=0)\n",
    "ecmodf = ecmodf.drop(columns=['sx_v', 'neut', 'cr'])\n",
    "print(ecmodf.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative round robin regression imputation maintains original clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(verbose=2, max_iter=20, min_value=0)\n",
    "ecmodf_impute = ecmodf.copy()\n",
    "imp.fit(ecmodf_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmodf = pd.DataFrame(imp.transform(ecmodf_impute), columns = ecmodf.columns, index = ecmodf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ecmodf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmodf['bmi'] = ecmodf['bmi'].astype('int64')\n",
    "ecmodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmodf_norm = ecmodf.copy()\n",
    "\n",
    "ecmodf_norm['ddim'] = np.log(ecmodf_norm['ddim']) #log conversion of skewed variables - days and sofa not included as would not expected to conform to a power law distribution\n",
    "ecmodf_norm['ferritin'] = np.log(ecmodf_norm['ferritin'])\n",
    "ecmodf_norm['pct'] = np.log(ecmodf_norm['pct'])\n",
    "ecmodf_norm['nlrat'] = np.log(ecmodf_norm['nlrat'])\n",
    "ecmodf_norm['lymph'] = np.log(ecmodf_norm['lymph'])\n",
    "ecmodf_norm['pplat'] = np.log(ecmodf_norm['pplat'])\n",
    "ecmodf_norm['pco2'] = np.log(ecmodf_norm['pco2'])\n",
    "ecmodf_norm['bmi'] = np.log(ecmodf_norm['bmi'])\n",
    "ecmodf_norm['sofa'] = np.log(ecmodf_norm['sofa'])\n",
    "\n",
    "ecmodf_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = preprocessing.MinMaxScaler(feature_range=(0.01, 1.01))\n",
    "ecmodf_normalized = normalize.fit_transform(ecmodf_norm)\n",
    "ecmodf_normalized = pd.DataFrame(ecmodf_normalized)\n",
    "ecmodf_normalized.columns = ecmodf_norm.columns\n",
    "ecmodf_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# A list holds the silhouette coefficients for each k\n",
    "silhouette_coefficients = []\n",
    "\n",
    "# Only works for 2 and above clusters as assesses inter-centroid distance\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "    kmeans.fit(ecmodf_normalized)\n",
    "    score = silhouette_score(ecmodf_normalized, kmeans.labels_)\n",
    "    silhouette_coefficients.append(score)\n",
    "    \n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, 10), silhouette_coefficients)\n",
    "plt.xticks(range(2, 10))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validclust.validclust import ValidClust #rapid assessment of optimal k using multiple tests\n",
    "\n",
    "data_temp = ecmodf_normalized.to_numpy()\n",
    "vclust = ValidClust(k=list(range(2, 9)), methods=['kmeans'])\n",
    "\n",
    "cvi_vals = vclust.fit_predict(data_temp)\n",
    "print(cvi_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vclust.plot() # darker cells indicate higher quality clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cluster prediction strength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/prediction-strength-a-simple-yet-relatively-unknown-way-to-evaluate-clustering-2e5eaf56643\n",
    "## Tibshirani R, Walther G. Cluster validation by prediction strength. J Comput Graph Stat 2005; 3: 511e28\n",
    "## Used in 10.1016/j.bja.2019.02.026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the range of k\n",
    "clusters = range(1, 10)\n",
    "\n",
    "# running the clustering \n",
    "wss_list = []\n",
    "\n",
    "for k in clusters:\n",
    "    model = KMeans(n_clusters=k)\n",
    "    model.fit(ecmodf_normalized)\n",
    "    wss_list.append(model.inertia_)\n",
    "\n",
    "# plotting\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(clusters, wss_list, '-o', color='black')\n",
    "ax.set(title='Elbow plot', \n",
    "       xlabel='number of clusters', \n",
    "       ylabel='WSS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = ecmodf_normalized.copy()\n",
    "temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "data_temp2 = ecmodf_normalized.to_numpy()\n",
    "X_train, X_test = train_test_split(data_temp2, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function to define closest centroid to given observation\n",
    "\n",
    "def get_closest_centroid(obs, centroids):\n",
    "    '''\n",
    "    Function for retrieving the closest centroid to the given observation \n",
    "    in terms of the Euclidean distance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : array\n",
    "        An array containing the observation to be matched to the nearest centroid\n",
    "    centroids : array\n",
    "        An array containing the centroids\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    min_centroid : array\n",
    "        The centroid closes to the obs \n",
    "    '''\n",
    "    min_distance = sys.float_info.max\n",
    "    min_centroid = 0\n",
    "    \n",
    "    for c in centroids:\n",
    "        dist = distance.euclidean(obs, c)\n",
    "        if dist < min_distance:\n",
    "            min_distance = dist\n",
    "            min_centroid = c\n",
    "            \n",
    "    return min_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main function that determines prediction strength of each cluster\n",
    "\n",
    "def get_prediction_strength(k, train_centroids, x_test, test_labels):\n",
    "    '''\n",
    "    Function for calculating the prediction strength of clustering\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        The number of clusters\n",
    "    train_centroids : array\n",
    "        Centroids from the clustering on the training set\n",
    "    x_test : array\n",
    "        Test set observations\n",
    "    test_labels : array\n",
    "        Labels predicted for the test set\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    prediction_strength : float\n",
    "        Calculated prediction strength\n",
    "    '''\n",
    "    n_test = len(x_test)\n",
    "    \n",
    "    # populate the co-membership matrix\n",
    "    D = np.zeros(shape=(n_test, n_test))\n",
    "    for x1, l1, c1 in zip(x_test, test_labels, list(range(n_test))):\n",
    "        for x2, l2, c2 in zip(x_test, test_labels, list(range(n_test))):\n",
    "            if tuple(x1) != tuple(x2):\n",
    "                if tuple(get_closest_centroid(x1, train_centroids)) == tuple(get_closest_centroid(x2, train_centroids)):\n",
    "                    D[c1,c2] = 1.0\n",
    "    \n",
    "    # calculate the prediction strengths for each cluster\n",
    "    ss = []\n",
    "    for j in range(k):\n",
    "        s = 0\n",
    "        examples_j = x_test[test_labels == j, :].tolist()\n",
    "        n_examples_j = len(examples_j)\n",
    "        for x1, l1, c1 in zip(x_test, test_labels, list(range(n_test))):\n",
    "            for x2, l2, c2 in zip(x_test, test_labels, list(range(n_test))):\n",
    "                if tuple(x1) != tuple(x2) and l1 == l2 and l1 == j:\n",
    "                    s += D[c1,c2]\n",
    "        ss.append(s / (n_examples_j * (n_examples_j - 0.9999))) \n",
    "\n",
    "    prediction_strength = min(ss)\n",
    "\n",
    "    return prediction_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the clustering \n",
    "strengths = []\n",
    "for k in clusters:\n",
    "    model_train = KMeans(n_clusters=k, random_state=42).fit(X_train)\n",
    "    model_test = KMeans(n_clusters=k, random_state=42).fit(X_test)\n",
    "    \n",
    "    pred_str = get_prediction_strength(k, model_train.cluster_centers_, X_test, model_test.labels_)\n",
    "    strengths.append(pred_str)\n",
    "\n",
    "# plotting\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(clusters, strengths, '-o', color='black')\n",
    "ax.axhline(y=0.8, c='red');\n",
    "ax.set(title='Determining the optimal number of clusters', \n",
    "       xlabel='number of clusters', \n",
    "       ylabel='prediction strength');\n",
    "\n",
    "##Should select maximum cluster for which prediction strength is above certain theshold (i.e. 3 in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## elbow and gap statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k, init='k-means++')\n",
    "    kmeanModel.fit(ecmodf_normalized)\n",
    "    inertia.append(kmeanModel.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, inertia, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('inertia')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "kl = KneeLocator(\n",
    "    range(1, 10), inertia, curve=\"convex\", direction=\"decreasing\"\n",
    ")\n",
    "\n",
    "kl.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gap_statistic import OptimalK\n",
    "\n",
    "optimalK = OptimalK(parallel_backend=None) #multicore\n",
    "optimalK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = optimalK(ecmodf_normalized, cluster_array=np.arange(1, 10))\n",
    "print('Optimal clusters: ', n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimalK.gap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(optimalK.gap_df.n_clusters, optimalK.gap_df.gap_value, linewidth=3)\n",
    "plt.scatter(optimalK.gap_df[optimalK.gap_df.n_clusters == n_clusters].n_clusters,\n",
    "            optimalK.gap_df[optimalK.gap_df.n_clusters == n_clusters].gap_value, s=250, c='r')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Cluster Count')\n",
    "plt.ylabel('Gap Value')\n",
    "plt.title('Gap Values by Cluster Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, init='k-means++', n_init=1000, n_jobs=-1).fit(ecmodf_normalized)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n",
    "plt.scatter(ecmodf_normalized['ferritin'], ecmodf_normalized['ddim'], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = kmeans.predict(ecmodf_normalized)\n",
    "ecmodf_clustered = pd.DataFrame(ecmodf)\n",
    "ecmodf_clustered['cluster'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmodf_clustered['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmodf_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
